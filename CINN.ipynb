{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "condition shape:  torch.Size([50, 1, 15])\n",
      "latent space shape:  torch.Size([50, 9])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from OScINN import OScINN1D\n",
    "\n",
    "# === Initialize the Conditional INN (cINN) ===\n",
    "oscinn = OScINN1D(9, 100, 8, cuda=False)  \n",
    "# Create a Conditional INN with:\n",
    "# - Input dimension: 9 (defines the dimensionality of the input dataset; each sample has 9 features).\n",
    "# - Conditional input dimension: 100 (dimensionality of the target property data; each condition has 100 features).\n",
    "# - Number of blocks: 8 (number of invertible coupling blocks in the INN).\n",
    "# - cuda: False (runs on CPU; set True to run on GPU).\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'  \n",
    "# Check if GPU is available; use 'cuda' if available, otherwise use 'cpu'.\n",
    "\n",
    "# === Generate Random Data for Testing ===\n",
    "c = c2 = torch.randn(50, 1, 100).to(device)  \n",
    "# Generate random conditional data to simulate the target property.\n",
    "# Shape: (50, 1, 100)\n",
    "# - 50 samples, each with a single 100-dimensional condition.\n",
    "\n",
    "x = torch.randn(50, 9).to(device)  \n",
    "# Generate random input data to simulate structures to be mapped.\n",
    "# Shape: (50, 9)\n",
    "# - 50 samples, each with 9 features (same as the input dimension of the cINN).\n",
    "\n",
    "# === Process Target Property Through the Conditional Network ===\n",
    "c = oscinn.cond_net(c)  \n",
    "# Pass the target property (c) through the `cond_net` to transform it into a learned representation.\n",
    "# Shape after this step: (50, 100)\n",
    "\n",
    "print('condition shape: ', c.shape)  \n",
    "# Print the shape of the transformed condition for verification.\n",
    "\n",
    "c = [c.squeeze() for i in range(8)]  \n",
    "# Prepare the transformed condition for use in all 8 invertible blocks.\n",
    "# The condition is repeated and squeezed to match the dimensionality expected by each block.\n",
    "\n",
    "# === Forward Mapping: Input Data to Latent Space ===\n",
    "z, jac_z = oscinn.cinn(x, c=c, rev=True)  \n",
    "# Map the input data (x) to the latent space (z) conditioned on the transformed condition (c).\n",
    "# - `rev=True` ensures the forward mapping direction (input → latent space).\n",
    "# Outputs:\n",
    "# - `z`: Latent space representation of the input data (Shape: 50 x 9).\n",
    "# - `jac_z`: Log Jacobian determinant for the transformation.\n",
    "\n",
    "print('latent space shape: ', z.shape)  \n",
    "# Print the shape of the latent space for verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test eval_forward...\n",
      "latent space shape:  torch.Size([50, 9])\n",
      "latent 1d space shape:  torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "# === Test `eval_forward` Method ===\n",
    "\n",
    "print('\\nTest eval_forward...')\n",
    "z, jac = oscinn.eval_forward([x, c2[:, 0]])  \n",
    "# Evaluate the cINN in forward mode using the `eval_forward` method.\n",
    "# Inputs:\n",
    "# - x: Input data (Shape: 50 x 9).\n",
    "# - c2[:, 0]: Raw target property data without additional dimension (Shape: 50 x 100).\n",
    "# Outputs:\n",
    "# - z: Latent space representation of x.\n",
    "# - jac: Log Jacobian determinant.\n",
    "\n",
    "print('latent space shape: ', z.shape)  \n",
    "# Print the latent space shape after using eval_forward.\n",
    "\n",
    "z_1D, jac_1D = oscinn.eval_forward([x[0], c2[0, 0]])  \n",
    "# Evaluate the forward pass for a single input sample (1D case).\n",
    "# Inputs:\n",
    "# - x[0]: First input sample (Shape: 9).\n",
    "# - c2[0, 0]: First target property (Shape: 100).\n",
    "# Outputs:\n",
    "# - z_1D: Latent space for the single input sample.\n",
    "# - jac_1D: Log Jacobian determinant for the transformation.\n",
    "\n",
    "print('latent 1d space shape: ', z_1D.shape)  \n",
    "# Print the shape of the latent space for a single input sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test eval_inverse...\n",
      "Initial z shape: torch.Size([50, 9])\n",
      "Initial c shape: torch.Size([50, 100])\n",
      "Adjusted c shape before cond_net: torch.Size([50, 1, 100])\n",
      "Processed c shape after cond_net: torch.Size([50, 1, 15])\n",
      "Prepared c shape for each block: 8 torch.Size([50, 15])\n",
      "Adjusted z shape: torch.Size([50, 9])\n",
      "Generated x_hat shape: torch.Size([50, 9])\n",
      "x_hat shape:  torch.Size([50, 9])\n"
     ]
    }
   ],
   "source": [
    "# === Test `eval_inverse` Method ===\n",
    "\n",
    "print('\\nTest eval_inverse...')\n",
    "x_hat, jac = oscinn.eval_inverse([z, c2[:, 0]])  \n",
    "# Perform the inverse mapping (latent space → input space) to reconstruct the input data.\n",
    "# Inputs:\n",
    "# - z: Latent space representation (Shape: 50 x 9).\n",
    "# - c2[:, 0]: Raw target property (Shape: 50 x 100).\n",
    "# Outputs:\n",
    "# - x_hat: Reconstructed input data (Shape: 50 x 9, matches input data shape).\n",
    "# - jac: Log Jacobian determinant.\n",
    "\n",
    "print('x_hat shape: ', x_hat.shape)  \n",
    "# Print the shape of the reconstructed input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial z shape: torch.Size([9])\n",
      "Initial c shape: torch.Size([100])\n",
      "Adjusted c shape before cond_net: torch.Size([2, 1, 100])\n",
      "Processed c shape after cond_net: torch.Size([2, 1, 15])\n",
      "Prepared c shape for each block: 8 torch.Size([2, 15])\n",
      "Adjusted z shape: torch.Size([2, 9])\n",
      "Generated x_hat shape: torch.Size([2, 9])\n",
      "x_hat 1d shape:  torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "x_1D, jac_1D = oscinn.eval_inverse([z[0], c2[0, 0]])  \n",
    "# Perform the inverse mapping for a single sample (1D case).\n",
    "# Inputs:\n",
    "# - z[0]: First latent space sample (Shape: 9).\n",
    "# - c2[0, 0]: First target property (Shape: 100).\n",
    "# Outputs:\n",
    "# - x_1D: Reconstructed input data for a single sample.\n",
    "# - jac_1D: Log Jacobian determinant.\n",
    "\n",
    "print('x_hat 1d shape: ', x_1D.shape)  \n",
    "# Print the shape of the reconstructed data for a single sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test training...\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.09s/it]\n"
     ]
    }
   ],
   "source": [
    "# === Training the cINN ===\n",
    "\n",
    "print('\\nTest training...')\n",
    "dataset = torch.utils.data.TensorDataset(x, c2[:, 0])  \n",
    "# Create a PyTorch dataset combining input data (x) and target property (c2[:, 0]).\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=5, shuffle=True, drop_last=False)  \n",
    "# Create a DataLoader for batching the dataset.\n",
    "# Batch size: 5 samples per batch.\n",
    "\n",
    "oscinn.optimizer = torch.optim.Adam  \n",
    "# Set the optimizer for training (Adam optimizer).\n",
    "\n",
    "oscinn.optimizer_kwargs = {'lr': 0.001}  \n",
    "# Set the learning rate for the optimizer.\n",
    "\n",
    "print(oscinn.optimizer)  \n",
    "# Print the optimizer settings for verification.\n",
    "\n",
    "oscinn.train(dataloader, 2)  \n",
    "# Train the cINN for 2 epochs using the provided DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating multiple samples for a target property...\n",
      "Initial target_property shape: torch.Size([1, 100])\n",
      "Expanded target_property shape for cond_net: torch.Size([1, 1, 100])\n",
      "Processed target_property shape (after cond_net): torch.Size([1, 1, 15])\n",
      "Processed target_property shape (after squeeze): torch.Size([1, 1, 15])\n",
      "Processed_condition shapes for blocks: [torch.Size([1, 1, 15]), torch.Size([1, 1, 15]), torch.Size([1, 1, 15]), torch.Size([1, 1, 15]), torch.Size([1, 1, 15]), torch.Size([1, 1, 15]), torch.Size([1, 1, 15]), torch.Size([1, 1, 15])]\n",
      "Latent vector z shape: torch.Size([1, 9])\n",
      "Initial z shape: torch.Size([1, 9])\n",
      "Initial c shape: torch.Size([1, 1, 15])\n",
      "Adjusted c shape before cond_net: torch.Size([1, 1, 1, 15])\n",
      "\n",
      "Error encountered while generating samples:\n",
      "Expected 2D (unbatched) or 3D (batched) input to conv1d, but got input of size: [1, 1, 1, 15]\n"
     ]
    }
   ],
   "source": [
    "print('\\nGenerating multiple samples for a target property...')\n",
    "\n",
    "# Define a target property\n",
    "target_property = torch.randn(1, 100).to(device)  # Shape: [1, 100]\n",
    "print(\"Initial target_property shape:\", target_property.shape)\n",
    "\n",
    "# Expand target property to match expected shape [Batch, Channels, Width]\n",
    "target_property = target_property.unsqueeze(1)  # Shape: [1, 1, 100]\n",
    "print(\"Expanded target_property shape for cond_net:\", target_property.shape)\n",
    "\n",
    "# Set cond_net to evaluation mode\n",
    "oscinn.cond_net.eval()\n",
    "\n",
    "# Process the target property through cond_net\n",
    "processed_target = oscinn.cond_net(target_property)  # Shape: [1, cond_dim, Width]\n",
    "print(\"Processed target_property shape (after cond_net):\", processed_target.shape)\n",
    "\n",
    "# Squeeze unnecessary dimensions while retaining batch compatibility\n",
    "processed_target = processed_target.squeeze(-1)  # Shape: [1, cond_dim]\n",
    "print(\"Processed target_property shape (after squeeze):\", processed_target.shape)\n",
    "\n",
    "# Prepare the condition for each block\n",
    "processed_condition = [processed_target for _ in range(oscinn.num_of_blocks)]  # Repeat for all blocks\n",
    "print(\"Processed_condition shapes for blocks:\", [pc.shape for pc in processed_condition])\n",
    "\n",
    "# Number of samples to generate\n",
    "num_samples = 5\n",
    "generated_samples = []\n",
    "\n",
    "for _ in range(num_samples):\n",
    "    # Sample a random latent vector z (Shape: [1, input_dim])\n",
    "    z = torch.randn(1, oscinn.input_dim).to(device)\n",
    "    print(\"Latent vector z shape:\", z.shape)\n",
    "\n",
    "    try:\n",
    "        # Use eval_inverse to generate a new sample\n",
    "        generated_sample, _ = oscinn.eval_inverse([z, processed_target])  # Pass z and processed condition\n",
    "        generated_samples.append(generated_sample)\n",
    "    except RuntimeError as e:\n",
    "        print(\"\\nError encountered while generating samples:\")\n",
    "        print(e)\n",
    "        break\n",
    "\n",
    "# Display the generated samples (if any)\n",
    "if generated_samples:\n",
    "    for i, sample in enumerate(generated_samples):\n",
    "        print(f\"Generated sample {i + 1}: {sample.cpu().numpy()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_samples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IDT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
